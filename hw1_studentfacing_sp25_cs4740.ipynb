{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VmFqIEb7CRO"
   },
   "source": [
    "# Homework 1 Section B: Named Entity Recognition (NER) with HMMs\n",
    "\n",
    "### Milestone Submission Due: February 12, 2025 (11:59PM)\n",
    "### Project Submission Due: February 21, 2025 (11:59PM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7n_cjoN7CRS"
   },
   "source": [
    "## **Logistics**\n",
    "\n",
    "### Notes:\n",
    "  \n",
    "- You will **NOT** be submitting this .ipynb file. Please refer to the submission instructions in both the hw1 pdf shared with you and at the end of this notebook.\n",
    "- Please complete the written questions in the same pdf document where you attempt Section A of the homework.\n",
    "- Do **NOT** add, remove, or modify any imports across python source files. If you have any concerns regarding missing imports, please let course staff know through EdStem before attempting to change anything.\n",
    "- Do **NOT** change any of the function headers and/or specs! The input(s) and output must perfectly match the specs, or else your implementation for any function with changed specs will most likely fail! (for e.g. do not shuffle your data when generating the output.txt file! )\n",
    "- If you decide to create local helper functions, your code must have docstrings/comments documenting the meaning of parameters and important parameter-like variables.\n",
    "- We are recommending python version 3.9+. This is due to compatibility issues with the external dependencies.\n",
    "\n",
    "\n",
    "### Tips:\n",
    "- Pair program the more intensive parts of this assignment! You'll thank yourselves later for the amount of trouble this helps you avoid.\n",
    "- We recommend you start this assignment early and continue incrementally adding onto it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yvrfpo597CRU"
   },
   "source": [
    "## Part 0: Environment setup\n",
    "\n",
    "**IMPORTANT:** Read the following file: `vscode-setup.md` to setup your environment for development including setting up VSCode, adding Python extensions, creating virtual environments, and installing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "JelKDZQH7CRU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "### AUTORELOAD EXTENSION -- DO NOT MODIFY ###\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "F7MTlknh7CRV"
   },
   "outputs": [],
   "source": [
    "### IMPORTS -- DO NOT MODIFY ###\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from helpers import apply_smoothing, handle_unknown_words\n",
    "from models import HMM\n",
    "from viterbi import viterbi\n",
    "from validation import evaluate_model, mean_f1, format_output_labels\n",
    "from data_exploration import unzip_data, read_json, stringify_labeled_doc, validate_ner_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIau-lWb7CRV"
   },
   "source": [
    "## Part 1: Data Exploration\n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "The data is stored in a zip file. You can use the following provided function to\n",
    "load the data and preprocess it. Under the hood, this is unzipping the data and reading each of\n",
    "the provided json data files into Python dictionaries. It then further formats the data such that\n",
    "we can accurately train our model from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "s6AG9AZj7CRW"
   },
   "outputs": [],
   "source": [
    "data_zip_path = \"./dataset.zip\"\n",
    "dest_path = \"dataset\"\n",
    "\n",
    "unzip_data(data_zip_path, dest_path) # unzips the data into current directory\n",
    "\n",
    "training_data = read_json(os.path.join(dest_path, \"train.json\"))\n",
    "validation_data = read_json(os.path.join(dest_path, \"val.json\"))\n",
    "test_data = read_json(os.path.join(dest_path, \"test.json\"))\n",
    "\n",
    "training_data['text'] = [sen[:-1] for sen in training_data['text']]\n",
    "validation_data['text'] = [sen[:-1] for sen in validation_data['text']]\n",
    "test_data['text'] = [sen[:-1] for sen in test_data['text']]\n",
    "\n",
    "training_data['NER'] = [sen[:-1] for sen in training_data['NER']]\n",
    "validation_data['NER'] = [sen[:-1] for sen in validation_data['NER']]\n",
    "\n",
    "training_data['index'] = [sen[:-1] for sen in training_data['index']]\n",
    "validation_data['index'] = [sen[:-1] for sen in validation_data['index']]\n",
    "test_data['index'] = [sen[:-1] for sen in test_data['index']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcFDvWtI7CRW"
   },
   "source": [
    "### Looking at the data\n",
    "\n",
    "Since your data files can be large and unwieldy, you can explore the data by\n",
    "writing code. Check out the data format by looking at at keys, and some of the\n",
    "values in the data. You can use the following code to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "UwCB5gdw7CRW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['index', 'text', 'NER'])\n",
      "dict_keys(['index', 'text', 'NER'])\n",
      "dict_keys(['index', 'text'])\n"
     ]
    }
   ],
   "source": [
    "print(training_data.keys())\n",
    "print(validation_data.keys())\n",
    "print(test_data.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6akC7Fv_7CRW"
   },
   "source": [
    "Notice the test data does not have any labels. This is because you will need to\n",
    "predict them using your models!\n",
    "\n",
    "To get a sense of what your data looks like, check out some samples. Implement\n",
    "the `stringify_labeled_doc` function in `data_exploration.py`, and use it to print\n",
    "out some samples of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PER Gavin Fogel] is cool.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"Gavin\", \"Fogel\", \"is\", \"cool\", \".\"]\n",
    "ner = [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\"]\n",
    "stringify_labeled_doc(text, ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "CEaFvG097CRW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "['He', 'was', 'President', 'of', 'the', 'Royal', 'Statistical', 'Society', ',', '1897', '–', '9']\n",
      "[('He', 'O'), ('was', 'O'), ('President', 'O'), ('of', 'O'), ('the', 'O'), ('Royal', 'B-ORG'), ('Statistical', 'I-ORG'), ('Society', 'I-ORG'), (',', 'O'), ('1897', 'O'), ('–', 'O'), ('9', 'O')]\n",
      "He was President of the [ORG Royal Statistical Society], 1897 – 9\n"
     ]
    }
   ],
   "source": [
    "# random_index = random.randint(0, len(training_data['text']))\n",
    "random_index = 83\n",
    "\n",
    "# TODO: fix cases with \"-\" and \"/\"\n",
    "# random_index = 13, 83\n",
    "# 33, 117, 2630\n",
    "\n",
    "text = training_data['text'][random_index]\n",
    "ner = training_data['NER'][random_index]\n",
    "\n",
    "print(random_index)\n",
    "print(text)\n",
    "print(list(zip(text, ner)))\n",
    "\n",
    "s = stringify_labeled_doc(text, ner)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the highest approval rate among [MISC West] [MISC German] federal states (average: 20%) and the second highest nationwide (national average: 24.3%)\n",
      "Cutting the skin into strips, she laid out her claim and founded an empire that would become, through the [MISC Punic Wars], the only existential threat to [LOC Rome] until the coming of the [PER Vandals] several centuries later\n",
      "Questions in [ORG Parliament] have not clarified the situation, as answers from the relevant minister say that since there is no official national anthem, each sport must make its own decision\n",
      "He is also remembered fondly by [LOC Distillery] fans\n",
      "The opening ceremonies were held separately in [LOC Christchurch], [LOC New Zealand] and [LOC Melbourne], [LOC Australia], on 12 February 2015, two days before the first two matches\n",
      "Then, everyone is asked to stand, join hands, and sing \"[MISC Auld Lang Syne]\" to bring the evening to an end\n",
      "Though [LOC Sweden] did not possess an extensive colonial network, botanical research based on [PER Carl Linnaeus] identified and developed techniques to grow cinnamon, tea and rice locally as an alternative to costly imports\n",
      "\"[MISC At Seventeen]\" is a bittersweet commentary on adolescent cruelty, the illusion of popularity and teenage angst, from the perspective of a narrator looking back on her earlier experience\n",
      "He hoped that it might regard him as its champion against the ambition of [PER Octavian], whom he presumed would not be willing to abandon his position in a similar manner\n",
      "In contrast, the [LOC White Nile] provides only 10% of the [LOC Nile]'s waters during the high-water season but contributes more than 80% during the low-water period\n",
      "This resulted in the nearby town of [LOC Alameda] being made an island\n",
      "It was well-received by critics It had a large opening weekend take of $35.5 million, placing it at #1 for the weekend of August 6 – 8, 2010, unseating \"[MISC Inception]\"\n",
      "His projects were carried out by the architect [PER Eugène Viollet-le-Duc]\n",
      "At, the [LOC Central African Republic] is the world's 45th - largest country (after [LOC Somalia])\n",
      "Red [MISC Easter] eggs are sometimes served along the centerline of tsoureki (braided loaf of bread)\n",
      "The mining industry of [LOC Laos] has received prominent attention with foreign direct investments\n",
      "A notable example is the [MISC Roman] poet [PER Juvenal]'s satires\n",
      "Nevertheless, the first BCP was a \"radical\" departure from traditional worship in that it \"eliminated almost everything that had till then been central to lay [MISC Eucharistic] piety\"\n",
      "He was also the voice behind many [ORG B&Q] adverts throughout 2006 / 2007\n",
      "In 2015, there were ten adult education centres in [LOC Gothenburg]: \"[LOC Agnesbergs] folkhögskola\", \"[ORG Arbetarrörelsens folkhögskola] i [LOC Göteborg]\", \"[ORG Finska folkhögskolan]\", \"[ORG Folkhögskolan i Angered]\", \"[ORG Göteborgs folkhögskola]\", \"[ORG Kvinnofolkhögskolan]\", \"[ORG Mo Gård folkhögskola]\", \"[ORG S: ta Birgittas folkhögskola]\", \"[ORG Västra Götalands folkhögskolor]\" and \"[ORG Wendelsbergs folkhögskola]\"\n",
      "The city's immediate proximity to two lakes, as well as [LOC Manistee National Forest], [LOC Pere Marquette State Forest], [LOC Mitchell State Park] and a number of major highways, has established tourism as a significant sector of the local economy\n",
      "The film also was a turning point in [PER Suriya]'s career\n",
      "In 1985 the channel's controller [PER Michael Grade] attempted to cancel the series, but this became an 18-month hiatus instead\n",
      "[PER Ralph H. Baer], while working at [ORG Sanders Associates] in 1966, came up with the idea of using a control system to play a rudimentary game of table tennis on a television screen\n",
      "On [MISC Metacritic], the film has a weighted average score of 43 out of 100, based on 34 critics, indicating \"mixed or average reviews\"\n",
      "In the year ending September 30, 2018, the airport had 133,669 operations, average 366 per day: 43% general aviation, 40% scheduled commercial, 17% air taxi, and From this station, the [LOC Antelope Valley Line] provides access to downtown [LOC Los Angeles] and the [LOC Antelope Valley]\n",
      "Other songs include \"[MISC Y.M.C.A.]\" (1979) and \"[MISC In the Navy]\" (1979)\n",
      "[MISC Game Revolution] described the storyline as \"epic\" and \"fabulous\" with \"many twists and turns\" and a large cast of characters\n",
      "This was the first time [LOC Wales] has held this trophy since 2005\n",
      "The genus \"Thambotricha\" from [LOC New Zealand] may be the sister group of all other extant members\n",
      "However, this was put on hold so she could concentrate on recording \"[MISC Destiny Fulfilled]\", the final studio album by [ORG Destiny's Child]\n",
      "It was subsequently made a state-owned territory (\"ager publicus\") and during the reign of the emperor [PER Augustus] it was imperial property\n",
      "The [LOC Chatham] oystercatcher is endemic to the [LOC Chatham Islands] of [LOC New Zealand] but is listed as endangered by the [ORG IUCN], while both the [MISC African] and [MISC Eurasian] oystercatchers are considered near threatened\n",
      "Thus, to convert from units of [PER Fahrenheit] to units of [PER Celsius], one subtracts 32 \"°F (the offset from the point of reference), divides by 9\" °F and multiplies by 5 \"°C (scales by the ratio of units), and adds 0\" °C (the offset from the point of reference)\n",
      "When [LOC Belgium] became independent in 1830 the national government started searching through their historical archives for people who could serve as national heroes\n",
      "He described his relationship with [ORG Chelsea] owner [PER Roman Abramovich] as \"excellent\" and expressed his desire to remain as [ORG Chelsea] manager until the end of the season\n",
      "They also propose that it is necessary to have a planetary system with large gas giants which provide bombardment protection without a hot [LOC Jupiter]; and a planet with plate tectonics, a large moon that creates tidal pools, and moderate axial tilt to generate seasonal variation\n",
      "as in his [MISC Apu] trilogy\n",
      "There are also commercial deposits being actively mined in the [LOC Northwest Territories] of [LOC Canada] and [LOC Brazil]\n",
      "The [PER Poincaré] conjecture claims that if such a space has the additional property that each loop in the space can be continuously tightened to a point, then it is necessarily a three-dimensional sphere\n",
      "She gives him food, and speaks to him, urging him not to \"have on his conscience the staggering burden of needless bloodshed\" (verse 31, [https://www.kingjamesbibleonline.org/ NIV]) and reminding him that [PER God] will make him a \"lasting dynasty\" (verse 28)\n",
      "It is the second film by director [PER Michel Brault]\n",
      "However, when consulting a map, she found that there was a city called [LOC Volterra] in the area where she had planned to place her imaginary city\n",
      "For example, the mold \"[LOC Scopulariopsis] brevicaulis\" produces significant amounts of trimethylarsine if inorganic arsenic is present\n",
      "This usage of the word is because the hyperboloid can be thought of as a sphere of imaginary radius, embedded in a [PER Minkowski] space\n",
      "Using the [PER Debye] model, the specific heat and entropy of a pure crystal are proportional to \"T\", while the enthalpy and chemical potential are proportional to \"T\"\n",
      "Many of [PER Newton]'s writings on alchemy are copies of other manuscripts, with his own annotations\n",
      "A 2015 survey of [MISC Android] users showed that persons 13 to 24 used messaging apps 3.5 times as much as those over 45, and were far less likely to use email\n",
      "[PER Ronaldo] is widely regarded as one of the two best players of his generation, alongside [PER Lionel Messi]\n",
      "Notable political activists and [MISC Thai] citizens who criticized the king or the institution of monarchy were often forced into exile or to suffer frequent imprisonments\n",
      "The park also protects the headwaters of the [LOC Fuji River], [LOC Ōi River] and [LOC Tenryū River]\n",
      "In contrast with the \"big-A anarchism\" of the classical era, the newly coined term \"small-a anarchism\" signals their tendency not to base their thoughts and actions on classical-era anarchism or to refer to classical anarchists such as [PER Peter Kropotkin] and [PER Pierre-Joseph Proudhon] to justify their opinions\n",
      "[ORG Intel] donated the use of a render farm for the production\n",
      "The team suffered a tragedy during spring training of, when a boat carrying pitchers [PER Steve Olin], [PER Tim Crews], and [PER Bob Ojeda] crashed into a pier\n",
      "He briefly teamed with songwriter [PER Bruce Woodley] of [ORG The Seekers]\n",
      "The main title sequence was designed by [PER Pablo Ferro] (1935 – 2018), who was also an uncredited editor on the film\n",
      "[ORG Ericsson] holds 33,000 granted patents, and is the number-one holder of [MISC GSM] / GPRS / EDGE, WCDMA / HSPA, and LTE essential patents\n",
      "The basic insights that both [PER Newton] and [PER Leibniz] provided were the laws of differentiation and integration, second and higher derivatives, and the notion of an approximating polynomial series\n",
      "Following a series of currency devaluations, the crown has remained stable in relation to the [LOC US] dollar\n",
      "These fables embed ancient morals and cultural lores that are also found in the fables and legends of [MISC Hindu] and [MISC Jain] texts\n",
      "He thus decided to offer [PER Rommel] the chance to take his own life\n",
      "However, although important for the local economy in [LOC Congo], the contribution of coltan mining in [LOC Congo] to the world supply of tantalum is usually small\n",
      "While their intent was to visit only small farms, the delegation chief was approached by farmer and corn salesman [PER Roswell Garst], who persuaded him to insist on visiting [PER Garst]'s large farm\n",
      "On 27 November 2017, [PER Vincenzo Montella] was sacked by [ORG A.C. Milan]\n",
      "He quickly became an automatic first-choice, as the [LOC Andalusia] side was eventually relegated\n",
      "He then moved to the [ORG Deutsche Eishockey Liga] in [LOC Germany] for [ORG ERC Ingolstadt] and then to the [MISC Elitserien] in [LOC Sweden] for [ORG Leksands IF]\n",
      "The double-axe, labrys, was the holy symbol of the [LOC Cretan] labyrinth\n",
      "He scored one further goal for [ORG Bari] that season\n",
      "[LOC Beryllium] has a large scattering cross section for high-energy neutrons, about 6 barns for energies above approximately 10 \"keV\n",
      "See e.g. [PER Robert Ulanowicz]'s treatment of ecosystems\n",
      "His draft record for [MISC World War I], which showed that he was born in 1875, was subsequently located\n",
      "Engine sheds were provided at major stations and on some branches including at [LOC Taunton railway station] and [LOC Exeter St Davids railway station]\n",
      "He was born in [LOC Bordeaux]\n",
      "[PER Huxley] identified agnosticism not as a creed but rather as a method of skeptical, evidence-based inquiry\n",
      "He is the General Secretary of the [ORG FijiFirst] party\n",
      "It was the top-line [ORG Chevelle] series that year positioned above the [LOC Malibu]\n",
      "While living in [LOC Milan], he studied light from the summit of [LOC Monte Rosa]\n",
      "During her first pregnancy, an old interest in gardening resurfaced and she attended [LOC Capel Manor] college to learn about horticulture, so as to create a garden for her children\n",
      "Between 64,000 and 79,000 [MISC Bosnian] [MISC Croats] were killed between April 1941 to May 1945\n",
      "[LOC Timișoara] is directly linked by train service with [LOC Budapest], [LOC Belgrade] and [LOC Vienna]\n",
      "She also joined the other stars of the concert, including [PER Sting], [PER Elton John], and [PER Billy Joel] to perform \"[MISC With a Little Help From My Friends]\" and \"[MISC Twist and Shout]\" with them\n",
      "He made a small appearance in the TV movie \"[MISC The Midnight Hour]\" (1985)\n",
      "[MISC Christmas] is the most extensively celebrated, and at least 24 to 26 December is taken as a holiday\n",
      "He was President of the [ORG Royal Statistical Society], 1897 – 9\n",
      "and has described [PER Oprah Winfrey] as \"the definition of inspiration and a strong woman\n",
      "Of equal importance is the [MISC TR-808] kick drum, an artificially pitch-downed or elongated bass drum sound sampled from [ORG Roland]'s classic [MISC TR-808] drum machine, and a sound which has been subject to an enormous amount of experimentation over the years\n",
      "A board resembling a draughts board was found in [LOC Ur] dating from 3000 BC\n",
      "The \"[MISC Eunos] 800\" was sold in [LOC Japan] from 1993 through 1998\n",
      "[LOC Halton] (which includes the towns of [LOC Runcorn] and [LOC Widnes]) and [LOC Warrington] became unitary authorities in 1998\n",
      "The wildlife, including lions, brown hyenas, cheetahs, leopards, wild dogs and antelope, was described in great detail in the best-selling book \"[MISC Cry of the Kalahari]\" by [PER Mark and Delia Owens]\n",
      "He was part of a £45 million spending spree for the club owned by [PER Jesús Gil] that season, alongside [PER Juninho Paulista]\n",
      "The full list of hyperbolic uniform honeycombs has not been proven and an unknown number of [PER non-Wythoffian] forms exist\n",
      "The game's only run, scored by the [ORG Dodgers], was unearned\n",
      "Most likely they traveled overland through the [LOC Appalachian Mountains] to the [MISC Scots-Irish] community in the [LOC Waxhaws], straddling the border between [LOC North] and [LOC South Carolina]\n",
      "He also appears in the sequel \"[MISC Star Wars: The Force Unleashed II]\" as the final boss\n",
      "In 1816, [PER François Magendie] discovered that dogs fed only carbohydrates (sugar), fat (olive oil), and water died evidently of starvation, but dogs also fed protein survived - identifying protein as an essential dietary component\n",
      "The city was transferred to [LOC Prussia] after the first partition of [LOC Poland] in 1772\n",
      "He was replaced by [PER Maureen Tucker], resulting in the \"classic\" lineup of [ORG the Velvet Underground]\n",
      "[LOC Mexico]'s agricultural exports increased 9.4 percent annually between 1994 and 2001, while imports increased by only 6.9 percent a year during the same period\n",
      "The [ORG Communist Party of the Soviet Union] called for a peaceful coexistence, where the war between the [LOC United States] and [LOC Soviet Union] would come to a close\n",
      "In 2018, the stone type needed for the construction was found in a quarry in [LOC Brinscall], near [LOC Chorley], [LOC England]\n",
      "However, he received a straight red card in a match against [ORG Liverpool] on 20 March 2011 after a foul on [PER Luis Suárez], although the card was later rescinded\n",
      "He signed as a free agent with the [ORG San Antonio Spurs] on August 2, 2000, but never played a game for them\n",
      "Developing a love of the country, he continued experimenting with ceremonial magic, working with [PER John Dee]'s [MISC Enochian] invocations\n",
      "\"to criticise the claims made by [PER Percival Lowell] that there were [MISC Martian] canals built by intelligent beings\n",
      "Visitors to the tripoint are strongly encouraged to first obtain permission from the nearest landowner or use the path from the arc corner monument, which is bordered by [LOC Delaware] parkland most of the way, and [LOC Pennsylvania] parkland the entire way\n",
      "With the 2011 expansion of the [ORG Pac-12 Conference], a new $3 \"billion contract for revenue sharing among all the schools in the conference was established\n",
      "[ORG Anheuser-Busch] has sponsored the [ORG CART] championship\n",
      "After reunification in 1990, [LOC Berlin] was made the capital of [LOC Germany]\n",
      "For the reconstruction, locations of the pillars were inferred through reference to the building's remains at [LOC Kuni-kyō], to where it had been relocated\n",
      "It was named for explorer [PER Christopher Columbus]\n",
      "These alleged apostates included leaders of [MISC Muslim] countries, since they failed to enforce \"sharia\" law\n",
      "The short film \"[MISC Alien Love Triangle]\" remains a 30-minute short film, and has never been released\n",
      "The village of [LOC Chenega] was transformed into an emergency base and media outlet\n",
      "It featured even more polished production, and continued the trend of the lead vocals extensively shared between members, although [PER Allen Lanier] did not sing lead\n",
      "The upper-level ramps on the [LOC Queens] end of the bridge were built during the same time\n",
      "A detailed listing of confirmed events was available on the website of the [ORG IEEE Information Theory Society]\n",
      "Since 1981, the municipality of [LOC Amsterdam] has gradually been divided into semi-autonomous boroughs, called \"stadsdelen\" or 'districts'\n",
      "The [LOC Kingdom of Kongo] existed from the 14th to the early 19th century\n",
      "With respect to real property, mechanic's liens are purely statutory devices that exist in every state (although in [LOC California], as noted below, they have a constitutional foundation)\n",
      "The rest of the teams were created \"ex novo\" as expansion teams or as charter members of the [ORG World Hockey Association], which merged with the [ORG NHL] in 1979\n",
      "[PER Andrew], who had postponed the crusade at least three times (in 1201, 1209 and 1213), finally agreed\n",
      "In [MISC Early Modern English], the word \"kitten\" was interchangeable with the now-obsolete word \"catling\"\n",
      "He obtained a degree in [ORG Economics] in 1976\n",
      "It is situated south-west of [LOC Bodmin Moor]\n",
      "It was awarded a gold disc in August 1977 by the [ORG BPI]\n",
      "There were homosexual castrati, as [PER Casanova]'s accounts of 18th - century [LOC Italy] bear witness\n",
      "to show [PER Jimmy Kimmel], her boyfriend at the time, a special video\n",
      "At its height it encompassed an area covering not only most of [LOC Chad], but also parts of southern [LOC Libya] ([LOC Fezzan]) and eastern [LOC Niger], northeastern [LOC Nigeria] and northern [LOC Cameroon]\n",
      "In 2019, homosexual acts were decriminalized in [LOC Angola], and the government also prohibited discrimination based on sexual orientation\n",
      "While strong forms of the various dialects are not fully mutually intelligible to northern [MISC Germans], communication is much easier in [LOC Bavaria], especially rural areas, where the [MISC Bavarian] [MISC dialect] still predominates as the mother tongue\n",
      "[MISC K10] processors came in dual-core, quad-core, and [MISC Spider] versions, with all cores on a single die\n",
      "The novel spent forty-six weeks on \"[ORG The New York Times]\" [MISC Best Seller List], including twenty-two weeks at number one\n",
      "In 1994, he became the head coach of the [ORG St. Petersburg Kickers]\n",
      "Megalithic tomb building continued into the [MISC Bronze Age] when metal began to be used for tools alongside the stone tools\n",
      "He turned down [PER W. S. Gilbert]'s offer of a collaboration, and wrote only two stage works between 1898 and 1914\n",
      "By late 2006, [ORG HP] had retaken the #1 sales position of PCs from [ORG Dell], which struggled with missed estimates and poor quality, and held that rank until supplanted in the mid-2010s by [ORG Lenovo]\n",
      "In his keynote address at the 2015 [MISC South by Southwest] music festival, he blamed [LOC Los Angeles]'s explosion of gang violence in the 1980s on the economic policies of [PER Ronald Reagan], and insinuated that his administration shipped guns and drugs into the area\n",
      "An attempt to advance into northern [LOC Germany] spearheaded by a major airborne operation in the [LOC Netherlands] failed\n",
      "Thirteen were built; two variants were also developed, including three of the [MISC YF-12] interceptor prototype, and two of the [MISC M-21] drone carrier\n",
      "Now see [MISC Neritoidea]\n",
      "He scored a twice in first match of the season, in [LOC Split] against [ORG RNK Split] and helping club to reach first victory in the season, 4 – 2\n",
      "The [LOC Port of Cape Town], the city's main port, is in [LOC Table Bay] directly to the north of the CBD\n",
      "There, she had a good start, defeating [PER Samantha Stosur] in the first round\n",
      "The [LOC Circus World Museum] houses life-size figures of the twins\n",
      "Despite a decline in adherence in the [ORG West], [MISC Christianity] remains the dominant religion in the region, with about 70% of the population identifying as [MISC Christian]\n",
      "He provided the new church with land in [LOC Canterbury], thus establishing one of the foundation stones of what ultimately became the [ORG Anglican Communion]\n",
      "Further mention of events in [LOC Kent] occurs in the late sixth century history of the [MISC Franks] by [PER Gregory of Tours]\n",
      "In 2025 [MISC Dutch] is in his late 70's, but his life has been extended unintentionally by administering him with captured predator medical-tech\n",
      "His contract was selected from the [ORG Lehigh Valley IronPigs] on June 27\n",
      "Originally scheduled for April 8, 1968, the [MISC 40th Academy Awards] ceremony was postponed for two days, because of the assassination of Dr. [PER Martin Luther King, Jr.]\n",
      "[LOC I-185] runs north about from its beginning to a junction with [LOC I-85] just east of [LOC LaGrange] and southwest of [LOC Atlanta]\n",
      "In 2000, she appeared in \"[MISC Things You Can Tell Just by Looking at Her]\" and \"[MISC Bash: Latter-Day Plays]\", later accompanying [PER Eve Ensler] to [LOC Kenya] in order to protest violence against women, particularly female genital mutilation\n",
      "Although a minor character in \"[MISC The Last Battle]\", much of the closing chapter is seen from her point of view\n",
      "\"Eristicophis\" is a monotypic genus created for the venomous viper species, \"Eristicophis macmahonii\", which is endemic to the desert region of [LOC Balochistan] near the borders of [LOC Iran], [LOC Pakistan], and [LOC Afghanistan]\n",
      "The [MISC Protestant] parishes preferred lateral churches, in which all the visitors could be as close as possible to the pulpit and the altar\n",
      "The final hit of his career came later that game, an RBI single against [PER Rollie Fingers] that snapped a 7 – 7 tie in the 12th inning\n",
      "In terms of GDP per capita [ORG Eurasian Economic Union] expects [LOC Armenia] to surpass neighboring [LOC Georgia] in 2019 and neighboring [LOC Azerbaijan] in 2020\n",
      "The cyborg ninja suit has been donned by multiple characters, most recently by the character [PER Raiden] in \"[MISC Metal Gear Solid 4: Guns of the Patriots]\"\n",
      "It spawned a sequel: \"[MISC The Whole Ten Yards]\" in 2004\n",
      "However, [LOC Wales] dropped off after the 60th minute, conceding three tries to lose the game 39 – 21\n",
      "Unlike in [LOC North America], where an average of two people a year are killed by bears, [LOC Scandinavia] only has records of three fatal bear attacks within the last century\n",
      "Most of the land just south of the dam and its immediate lakeshore is part of [LOC Pickwick Landing State Park], and [LOC Shiloh National Military Park] is located a few miles to the north\n",
      "In 2013, damage caused by a sniper attack at an electrical substation in [LOC California] threatened power distribution throughout [LOC Silicon Valley]\n",
      "[PER Ira Gershwin], as heir to his brother, consistently refused to permit these productions to be staged\n",
      "However, [ORG Issas] are predominate in the government, civil service, and the ruling party\n",
      "He also made generous donations of \"jagirs\" to many temples to gain the goodwill of his [MISC Hindu] subjects\n",
      "The [ORG Allentown Symphony Orchestra], conducted by [PER Diane Wittry] since 1995, performs fall through spring at the historic [LOC Miller Symphony Hall]\n",
      "they received their insignia from Queen [PER Elizabeth II] at an investiture at [LOC Buckingham Palace] on 26 October\n",
      "In rugby union, [ORG Saracens F.C.] incorporates the crescent and star in its club emblem\n",
      "In [MISC Prakrit] and [MISC Pāli], it is rendered \"dhamma\"\n",
      "The game then shifts forward eight months, by which time the [ORG Predators] have established a camp around the artifact\n",
      "In the beginning, the [ORG Enosis] movement had only few supporters mainly from the upper classes\n",
      "By comparison the [MISC Harvard Mark I] could perform the same task in just six seconds\n",
      "However the [MISC Indo-European] component of [PER Apollo] does not explain his strong relation with omens, exorcisms, and with the oracular cult\n",
      "Further success followed in 1732 with his play \"[MISC Zaïre]\", which when published in 1733 carried a dedication to [PER Fawkener] praising [MISC English] liberty and commerce\n",
      "This was a key turning point in the [MISC Battle of the Atlantic], enabling the [ORG Royal Air Force], the [ORG U.S. Army Air Forces], and the [ORG U.S. Navy] to provide aerial coverage in the [LOC Mid-Atlantic] gap\n",
      "The following season saw him named as the club's player of the season, but he was then released by new manager [PER Keith Curle]\n",
      "This type of vessel came to be known as the \"battlecruiser\", and the first were commissioned into the [ORG Royal Navy] in 1907\n",
      "His cousins included the composer [PER Nicolas Nabokov]\n",
      "These snippets of [MISC SQL] code can address external data sources through the use of [MISC ODBC] connections on the local machine\n",
      "Nearly half (52%) of the empire's railways were built in [LOC Hungary], thus the railroad density there became higher than that of [LOC Cisleithania]\n",
      "Otherwise, the changes must be reevaluated manually when [MISC Emacs] is restarted\n",
      "While there, he initiated an important series of historical monographs on the history of [LOC Malaya], publishing the first in 1960\n",
      "In 1850 it was declared a free trade port, with the liquor, salt, arms, and opium trades developing duties as it won all the coffee trade from [LOC Mokha]\n",
      "His emphasis on placing his own work on a par with the [MISC Qur'an] led conservative clerics to accuse him of \"shirk\", furthering their opposition to his regime\n",
      "The most consumed carbonated soft drinks are produced by three major global brands: [ORG Coca-Cola], [ORG PepsiCo] and the [ORG Dr Pepper Snapple Group]\n",
      "He is still able to have sexual intercourse but is sterile due to an infection caught in [LOC Burma]\n",
      "In the following event (a pursuit), he was beaten at the finish line by teammate [PER Emil Hegle Svendsen], but won the pursuit cup\n",
      "In 2017 [ORG Premier Bank] from [LOC Mogadishu] opened a branch in [LOC Hargeisa]\n",
      "His brothers [PER Enrique] and [PER Jesús] were also active in politics\n",
      "Statistical detections of inactive comet nuclei in the [LOC Kuiper] belt have been reported from observations by the [MISC Hubble Space Telescope] but these detections have been questioned\n",
      "It was formed during the [MISC Holocene] period\n",
      "The 1895 pastel-on-board version of the work, owned by [MISC Norwegian] businessman [PER Petter Olsen], sold at [LOC Sotheby's] in [LOC London] for a record price of nearly [LOC US] $120 million at auction on 2 May 2012\n",
      "302 batting average in 1924 and, in a year-end poll of major league baseball players, he was a near-unanimous selection as the best third baseman in the [ORG American League]\n",
      "[LOC Colorado] has recorded 525 earthquakes since 1973, a majority of which range 2to 3.5 on the Richter scale\n",
      "[LOC Estonia] is a flat country covering\n",
      "In 2006, openly gay rabbinic candidates were also to be admitted into the [ORG JTS]\n",
      "Four wheels were recorded in 1895, and a set of tilt hammers from the site were rescued and moved to [LOC Abbeydale Industrial Hamlet]\n",
      "[PER Nicholas] was born in January 1962\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    text = training_data['text'][i]\n",
    "    ner = training_data['NER'][i]\n",
    "    s = stringify_labeled_doc(text, ner)\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YMAffHm7CRW"
   },
   "source": [
    "#### Q1.1: Using the `stringify_labeled_doc` function you implemented, print 5 documents (sentences) from the training data which have at least 4 distinct tags (including 'O'). What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "hPHzp5l07CRX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutting the skin into strips, she laid out her claim and founded an empire that would become, through the [MISC Punic Wars], the only existential threat to [LOC Rome] until the coming of the [PER Vandals] several centuries later\n",
      "The [LOC Chatham] oystercatcher is endemic to the [LOC Chatham Islands] of [LOC New Zealand] but is listed as endangered by the [ORG IUCN], while both the [MISC African] and [MISC Eurasian] oystercatchers are considered near threatened\n",
      "He then moved to the [ORG Deutsche Eishockey Liga] in [LOC Germany] for [ORG ERC Ingolstadt] and then to the [MISC Elitserien] in [LOC Sweden] for [ORG Leksands IF]\n",
      "In his keynote address at the 2015 [MISC South by Southwest] music festival, he blamed [LOC Los Angeles]'s explosion of gang violence in the 1980s on the economic policies of [PER Ronald Reagan], and insinuated that his administration shipped guns and drugs into the area\n",
      "Further mention of events in [LOC Kent] occurs in the late sixth century history of the [MISC Franks] by [PER Gregory of Tours]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "count = 0\n",
    "\n",
    "for i in range(7000):\n",
    "    text = training_data['text'][i]\n",
    "    ner = training_data['NER'][i]\n",
    "    tags = [x.split(\"-\")[-1] for x in ner]\n",
    "    if len(list(set(tags))) >= 4:\n",
    "        s = stringify_labeled_doc(text, ner)\n",
    "        print(s)\n",
    "        count += 1\n",
    "    if count == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Q1.1 Answer</mark>\n",
    "\n",
    "I noticed that in most cases, each word in a named entity is capitalized, which makes sense because they are supposed to be proper nouns. Also, most entities are only 1-3 words long. Additionally, even in sentences where there are more than 3 kinds of named entities, most of the tokens in the sentence are still tagged as \"O\", meaning they are not part of an entity. Therefore, it seems that the dataset is quite unbalanced and biased towards \"O\" tokens. Finally, I also noticed that a many named entities (though not all) follow prepositions such as \"by\", \"of\", \"for\", \"in\", and \"to\". This may be helpful in the NER task because prepositions are a closed class of words, so the model may be able to quickly learn all of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H45c58Vr7CRX"
   },
   "source": [
    "### Validating the data\n",
    "\n",
    "This data looks okay, _right?_ ... _right?_ The reality is that language data is\n",
    "super messy. One option would be to look through every example by hand, but this\n",
    "is impractical. Another option would be to write a program that could check if\n",
    "each example is correct, but if you could do that, you wouldn't need to write\n",
    "the program to do NER tagging in the first place! However, there is a middle\n",
    "ground. If you had a programatic way to check the validity of the data, you\n",
    "could catch some of these issues. Let's try to do that.\n",
    "\n",
    "#### Q1.2: Implement the `validate_ner_sequence` function in `data_exploration.py` Are there any documents in the training data which have invalid labelings? If so, how many are there?\n",
    "\n",
    "Hint: Think about what makes a valid sequence of labels under the BIO tagging scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'B-MISC', 'O', 'B-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-LOC', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'B-LOC', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'B-MISC', 'O', 'B-MISC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O']\n",
      "['O', 'I-MISC', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-PER']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'I-MISC', 'O']\n",
      "['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O']\n",
      "['B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC']\n",
      "['O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'B-ORG', 'I-ORG', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'B-LOC', 'I-LOC', 'O']\n",
      "['O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'I-MISC', 'O', 'O', 'B-PER']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O']\n",
      "['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-MISC', 'O', 'B-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O']\n",
      "['O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'I-MISC', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'B-LOC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'I-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER']\n",
      "['O', 'O', 'O', 'B-LOC', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'I-MISC', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-PER', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'I-MISC', 'O', 'O', 'B-PER', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-PER', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'I-MISC', 'O', 'O', 'O', 'B-LOC', 'I-LOC']\n",
      "['O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'B-PER', 'I-PER']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'B-PER', 'I-PER', 'I-PER']\n",
      "['O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'I-MISC', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'I-MISC', 'O', 'I-MISC', 'O', 'O', 'B-LOC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'B-PER', 'I-PER']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'B-PER', 'I-PER']\n",
      "['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC']\n",
      "['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-LOC']\n",
      "['O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'B-PER', 'O', 'I-MISC', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC']\n",
      "['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-ORG', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'I-MISC', 'I-MISC', 'B-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O']\n",
      "['O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O']\n",
      "['B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O']\n",
      "['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'B-LOC']\n",
      "['O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'B-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'I-LOC']\n",
      "['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'I-MISC', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'B-LOC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'I-MISC']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(7000):\n",
    "    ner = training_data['NER'][i]\n",
    "    valid = validate_ner_sequence(ner)\n",
    "    if not valid:\n",
    "        count += 1\n",
    "        print(ner)\n",
    "\n",
    "count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Q1.2 Answer</mark>\n",
    "\n",
    "There are 194 documents in the training data (out of 7000) that have an invalid NER sequence, meaning there are some invalid sequences but 97.2% of them are valid. In all of the invalid cases, it seems like the error results from an \"O\" transitioning directly to an \"I\" tag, rather than an \"I\" tag directly following a \"B\" or \"I\" tag of another type (e.g. LOC to MISC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Statistics\n",
    "\n",
    "In order to look at the data in a different way, you can visualize some of its characteristics. Take the example\n",
    "below, which shows the distribution of the number of tokens per document in the training data. You can use the following code to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "V6VQ_7gK7CRX"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_lengths = [len(doc) for doc in training_data[\"text\"]]\n",
    "\n",
    "def plot_histogram(data, title, xlabel, ylabel, bins=50):\n",
    "  \"\"\"\n",
    "  Plots a histogram of the data.\n",
    "\n",
    "  Input:\n",
    "    data: List[Int], representing the data to be plotted\n",
    "    title: String, representing the title of the plot\n",
    "    x_label: String, representing the x-axis label\n",
    "    y_label: String, representing the y-axis label\n",
    "    i: Int, representing the figure number\n",
    "  Output:\n",
    "    None\n",
    "  \"\"\"\n",
    "  plt.hist(data, bins=bins, color=\"maroon\")\n",
    "  plt.xlabel(xlabel)\n",
    "  plt.ylabel(ylabel)\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "plot_histogram(\n",
    "\t\tdoc_lengths,\n",
    "\t\t\"Distribution of document length\",\n",
    "\t\t\"Document Length\",\n",
    "\t\t\"Count\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvM9s7J97CRX"
   },
   "source": [
    "#### Q1.3: Provide a bar graph giving the token level distribution of NER tags, (O included): e.g. 10% of tokens are B-ORG, 20% of tokens are I-ORG, etc. What do you notice about this distribution? Is this what you might expect? What difficulties might this cause for your models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of NER tags')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "tags, counts = np.unique(sum(training_data[\"NER\"], []), return_counts=True)\n",
    "frequency = counts / np.sum(counts) * 100\n",
    "\n",
    "plt.bar(tags, frequency)\n",
    "plt.xlabel(\"NER tag\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of NER tags\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.57055976,  1.73700082,  1.18549205,  1.90698641,  0.88896164,\n",
       "        1.57834761,  1.00291494,  1.35107059, 87.77866618])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Q1.3 Answer</mark>\n",
    "\n",
    "I noticed that more than 87% of the NER tags in the training dataset are \"O\", meaning they are not part of any named entity. The frequencies of the \"I\" and \"B\" tags ranges from 0.89% to 2.57%, meaning that within the tags that are part of a named entity, the classes have relatively balanced distributions. It is not surprising to me that most of the tokens in the datasets are tagged as \"O\", since the proportion of words in everyday speech that are proper nouns is quite small. Additionally, there are a lot of function words in English (as opposed to content words), all of which would be tagged as \"O\". This distribution might cause some difficulties for our model, since it just learn to predict \"O\" for everything since it is by far the most common tag (meaning this simple baseline already has an accuracy of 87%!) Additionally, this means that the model must be trained on a lot of data in order to be exposed to enough \"I\" and \"B\" tags to learn how to identify them, since they are so uncommon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gitXbGWG7CRX"
   },
   "source": [
    "#### Q1.4: It seems to be that entity tokens are uppercase. Is this correct? Plot a 2x2 matrix displaying the counts, where one dimension represents whether a token is uppercase and the other dimension indicates whether the token is part of an entity. What do you notice about this distribution? Is this what you might expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "qg1x0IHF7CRX"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Initialize category counters\n",
    "categories = {\n",
    "    \"Upper, e\": 0,\n",
    "    \"Upper, ne\": 0,\n",
    "    \"Lower, e\": 0,\n",
    "    \"Lower, ne\": 0\n",
    "}\n",
    "\n",
    "# Process the training data\n",
    "for text, ner in zip(training_data[\"text\"], training_data[\"NER\"]):\n",
    "    for word, tag in zip(text, ner):\n",
    "        is_upper = word[0].isupper()\n",
    "        is_entity = (tag != \"O\")\n",
    "        \n",
    "        if is_upper and is_entity:\n",
    "            categories[\"Upper, e\"] += 1\n",
    "        elif is_upper and not is_entity:\n",
    "            categories[\"Upper, ne\"] += 1\n",
    "        elif not is_upper and is_entity:\n",
    "            categories[\"Lower, e\"] += 1\n",
    "        else:\n",
    "            categories[\"Lower, ne\"] += 1\n",
    "\n",
    "# Create the confusion matrix\n",
    "matrix = np.array([\n",
    "    [categories[\"Upper, e\"], categories[\"Upper, ne\"]],\n",
    "    [categories[\"Lower, e\"], categories[\"Lower, ne\"]],\n",
    "])\n",
    "\n",
    "# Plot the matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(matrix, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "plt.xticks([0, 1], [\"Entity\", \"Non-Entity\"])\n",
    "plt.yticks([0, 1], [\"Uppercase\", \"Lowercase\"])\n",
    "\n",
    "# Annotate the matrix\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, matrix[i, j], ha=\"center\", va=\"center\", color=\"black\", fontsize=12)\n",
    "\n",
    "plt.title(\"Entity Capitalization Matrix\")\n",
    "plt.xlabel(\"Entity Status\")\n",
    "plt.ylabel(\"Capitalization\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPlG0lZx7CRX"
   },
   "source": [
    "#### Q1.5: Provide a list of the 10 tokens which are most frequently tagged as part of a named entity. What do you notice about this distribution? What difficulties might this cause for your models?\n",
    "\n",
    "For examples if\n",
    "- tokens = [\"Cornell\", \"University\", \"is\", \"a\", \"university\", \"in\", \"Ithaca\", \",\", \"New\", \"York\"]\n",
    "- tags   = [\"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\", \"B-LOC\", \"I-LOC\"]\n",
    "\n",
    "In this example, there are 3 named entities:\n",
    "- [\"Cornell University\", \"Ithaca\", \"New York\"].\n",
    "\n",
    "However, you are only interested in tokens which are tagged as part of named entities, which would be [\"Cornell\", \"University, \"Ithaca\", \"New\", \"York\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "mVqeORv_7CRX"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EuI2qdvtgTJ"
   },
   "source": [
    "#### Q1.6: Provide a scatter plot mapping the length of a document to the number of named entities in that document. Describe what the plot looks like, and what it might mean about the relationship between named entities and document length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "BylcxFsXtgTJ"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_gTE2BI7CRX"
   },
   "source": [
    "#### Q1.7: Make a convincing arugment around a novel insight about the data. In only a few sentences, argue why this insight is important in understanding the data for this task, and support your answer with relevant graphs or statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Wp8QeBcG7CRX"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGonsYOV7CRX"
   },
   "source": [
    "## Part 2: Hidden Markov Model\n",
    "In this part of the assignment, you will:\n",
    "1. Implement code for counting and smoothing of labels and words, as well as unknown word handing, as necessary to support the Viterbi algorithm.\n",
    "2. Build a Hidden Markov Model in accordance with the starter code that has been provided in `models.py`.\n",
    "3. Implement the **Viterbi algorithm**, that can be used to infer token-level labels (identifying the appropriate named entity) for an input document. This process is commonly referred to as **decoding**. Bigram-based Viterbi is $ \\mathcal{O}(sm^2)$ where *s* is the length of the sentence and *m* is the number of tags. Your implementation should have similar efficiency.\n",
    "\n",
    "### Unknown Word Handling\n",
    "---\n",
    "Handling unknown words is essential for improving the robustness of your sequence tagging model. When your model encounters words that were not present in the training data, it might struggle to make accurate predictions.\n",
    "\n",
    "In this section, you will complete `handle_unknown_words(t, documents)` function in `helpers.py` The unknown word handling function replaces infrequently occurring words in the text data with a special \"\\<unk\\>\" token. This ensures that words with low occurrence are not treated as unique and distinct, allowing the model to recognize them as a common unknown category. By doing so, the method helps the model maintain consistent performance when dealing with unfamiliar or rare words, enhancing its ability to handle unseen data effectively.\n",
    "\n",
    "Detailed specs about expected inputs and outputs are outlined in `helpers.py`. It injests the tokenized documents of a corpus (e.g. the training_data[\"text\"] from above) and returns a tokenized document corpus with infrequent words replaced by \"\\<unk\\>\", as well as the resulting vocab.\n",
    "\n",
    "After you complete the function, you may run the following basic test case. Passing this test does NOT guarantee correctness and it is a good idea to write some tests of your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['apple', 'banana', 'apple', '<unk>'],\n",
       "  ['apple', 'cherry', 'banana', 'banana'],\n",
       "  ['cherry', 'apple', 'banana']],\n",
       " ['banana', 'apple', 'cherry', '<unk>'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0.3\n",
    "documents = [[\"apple\", \"banana\", \"apple\", \"orange\"],\n",
    "                [\"apple\", \"cherry\", \"banana\", \"banana\"],\n",
    "                [\"cherry\", \"apple\", \"banana\"]]\n",
    "\n",
    "handle_unknown_words(t=t, documents=documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "one7Ub_17CRX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['good', 'morning'], ['is', 'good', 'morning'], ['<unk>']]\n",
      "[['good', 'morning'], ['is', 'good', 'morning'], ['<unk>']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['morning', 'good', 'is', '<unk>']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0.3  #see helpers.py for information about this parameter means\n",
    "documents = [[\"good\", \"morning\"], [\"is\", \"good\", \"morning\"], [\"hello\"]]\n",
    "expected_new_documents = [[\"good\", \"morning\"], [\"is\", \"good\", \"morning\"], [\"<unk>\"]]\n",
    "expected_vocab = [\"good\", \"morning\", \"is\", \"<unk>\"]\n",
    "new_documents, vocab = handle_unknown_words(t, documents)\n",
    "\n",
    "print(expected_new_documents)\n",
    "print(new_documents)\n",
    "\n",
    "assert expected_new_documents == new_documents\n",
    "assert sorted(expected_vocab) == sorted(vocab)\n",
    "\n",
    "# TODO: test this a bit more\n",
    "vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apple', 'banana', 'apple', '<unk>'], ['apple', 'cherry', 'banana', 'banana'], ['cherry', 'apple', 'banana']]\n",
      "[['apple', 'banana', 'apple', '<unk>'], ['apple', 'cherry', 'banana', 'banana'], ['cherry', 'apple', 'banana']]\n"
     ]
    }
   ],
   "source": [
    "t = 0.3\n",
    "documents = [[\"apple\", \"banana\", \"apple\", \"orange\"],\n",
    "                [\"apple\", \"cherry\", \"banana\", \"banana\"],\n",
    "                [\"cherry\", \"apple\", \"banana\"]]\n",
    "new_documents, vocab = handle_unknown_words(t, documents)\n",
    "expected_new_documents = [['apple', 'banana', 'apple', '<unk>'],\n",
    " ['apple', 'cherry', 'banana', 'banana'],\n",
    " ['cherry', 'apple', 'banana']]\n",
    "expected_vocab = ['banana', 'apple', 'cherry', '<unk>']\n",
    "\n",
    "print(expected_new_documents)\n",
    "print(new_documents)\n",
    "\n",
    "assert expected_new_documents == new_documents\n",
    "assert sorted(expected_vocab) == sorted(vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvD6P8Qp7CRY"
   },
   "source": [
    "### Smoothing\n",
    "---\n",
    "Smoothing makes our sequence tagging model more resilient to unexpected words and rare patterns, improving its ability to predict accurately on unseen data.\n",
    "\n",
    "In this section, you will complete `apply_smoothing(k, observation_counts, unique_obs)` function in `helpers.py` file. The function implements an add-k smoothing. It adds a constant value (k) to each count before calculating probabilities, ensuring that no count is zero and that probabilities are never zero. While there are more advanced smoothing techniques, add-k smoothing provides a good starting point for handling the challenges of sparse data in probabilistic modeling.\n",
    "\n",
    "For example, given an unsmoothed frequency count\n",
    "```\n",
    "unsmoothed_counts = {\n",
    "    ('PER', 'John'): 3,\n",
    "    ('PER', 'Google'): 0,\n",
    "    ('PER', 'California'): 0,\n",
    "    ('PER', 'works'): 0,\n",
    "    ('PER', 'at'): 0,\n",
    "    ('ORG', 'Google'): 2,\n",
    "    ('ORG', 'John'): 0,\n",
    "    ('ORG', 'California'): 0,\n",
    "    ('ORG', 'works'): 0,\n",
    "    ('ORG', 'at'): 0,\n",
    "    ('LOC', 'Google'): 0,\n",
    "    ('LOC', 'John'): 0,\n",
    "    ('LOC', 'California'): 1,\n",
    "    ('LOC', 'works'): 0,\n",
    "    ('LOC', 'at'): 0,\n",
    "    ('O', 'Google'): 0,\n",
    "    ('O', 'John'): 0,\n",
    "    ('O', 'California'): 0,\n",
    "    ('O', 'works'): 4,\n",
    "    ('O', 'at'): 5,\n",
    "}\n",
    "```\n",
    "the smoothed add-1 frequency count should be\n",
    "```\n",
    "smoothed_counts = {\n",
    "    ('PER', 'John'): 3 + 1,\n",
    "    ('PER', 'Google'): 0 + 1,\n",
    "    ('PER', 'California'): 0 + 1,\n",
    "    ('PER', 'works'): 0 + 1,\n",
    "    ('PER', 'at'): 0 + 1,\n",
    "    ('ORG', 'Google'): 2 + 1,\n",
    "    ('ORG', 'John'): 0 + 1,\n",
    "    ('ORG', 'California'): 0 + 1,\n",
    "    ('ORG', 'works'): 0 + 1,\n",
    "    ('ORG', 'at'): 0 + 1,\n",
    "    ...same for 'LOC' and 'O'\n",
    "}\n",
    "```\n",
    "and the smoothed add-1 probability would be\n",
    "```\n",
    "smoothed_prob = {\n",
    "    ('PER', 'John'): (3 + 1) / (3 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1),\n",
    "    ('PER', 'Google'): (0 + 1) / (3 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1),\n",
    "    ('PER', 'California'): (0 + 1) / (3 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1),\n",
    "    ('PER', 'works'): (0 + 1) / (3 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1),\n",
    "    ('PER', 'at'): (0 + 1) / (3 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1),\n",
    "    ('ORG', 'Google'): (2 + 1) / (2 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1),\n",
    "    ...\n",
    "}\n",
    "```\n",
    "Note when you call `apply_smoothing` function later in the HMM, the input `observation_counts` should contain counts for all possible `(curr NER tag, next NER tag)` pairs for transition matrix and `(NER tag, word)` pairs for emission matrix. i.e. if a `(NER tag, word)` doesn't appear in the training data, you should still include it as `observation_counts[(NER tag, word)]=0`.\n",
    "\n",
    "After you complete the function, you may run the following basic test case. Passing this test does NOT guarantee correctness and it is a good idea to write some tests of your own. <br>\n",
    "\n",
    "**NOTE: This example uses entity tags, but you should be using BIO tags in the assignment (ex: B-ORG, I-ORG, B-PER, I-PER, B-LOC, I-LOC, B-MISC, I-MISC, O).**\n",
    "\n",
    "**In your implementation, you should store values in the log space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "FOo0c4B87CRY"
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "test_counts = {\n",
    "    ('PER', 'John'): 3,\n",
    "    ('PER', 'Google'): 0,\n",
    "    ('PER', 'California'): 0,\n",
    "    ('PER', 'works'): 0,\n",
    "    ('PER', 'at'): 0,\n",
    "    ('ORG', 'Google'): 2,\n",
    "    ('ORG', 'John'): 0,\n",
    "    ('ORG', 'California'): 0,\n",
    "    ('ORG', 'works'): 0,\n",
    "    ('ORG', 'at'): 0,\n",
    "    ('LOC', 'Google'): 0,\n",
    "    ('LOC', 'John'): 0,\n",
    "    ('LOC', 'California'): 1,\n",
    "    ('LOC', 'works'): 0,\n",
    "    ('LOC', 'at'): 0,\n",
    "    ('O', 'Google'): 0,\n",
    "    ('O', 'John'): 0,\n",
    "    ('O', 'California'): 0,\n",
    "    ('O', 'works'): 4,\n",
    "    ('O', 'at'): 5,\n",
    "}\n",
    "\n",
    "expected_log_smoothed_probs = {\n",
    "    ('PER', 'John'): np.log(4/8),\n",
    "    ('PER', 'Google'): np.log(1/8),\n",
    "    ('PER', 'California'): np.log(1/8),\n",
    "    ('PER', 'works'): np.log(1/8),\n",
    "    ('PER', 'at'): np.log(1/8),\n",
    "    ('ORG', 'Google'): np.log(3/7),\n",
    "    ('ORG', 'John'): np.log(1/7),\n",
    "    ('ORG', 'California'): np.log(1/7),\n",
    "    ('ORG', 'works'): np.log(1/7),\n",
    "    ('ORG', 'at'): np.log(1/7),\n",
    "    ('LOC', 'Google'): np.log(1/6),\n",
    "    ('LOC', 'John'): np.log(1/6),\n",
    "    ('LOC', 'California'): np.log(2/6),\n",
    "    ('LOC', 'works'): np.log(1/6),\n",
    "    ('LOC', 'at'): np.log(1/6),\n",
    "    ('O', 'Google'): np.log(1/14),\n",
    "    ('O', 'John'): np.log(1/14),\n",
    "    ('O', 'California'): np.log(1/14),\n",
    "    ('O', 'works'): np.log(5/14),\n",
    "    ('O', 'at'): np.log(6/14),\n",
    "}\n",
    "\n",
    "vocab = ['John', 'Google', 'California', 'works', 'at']\n",
    "# vocab = [\"PER\", \"ORG\", \"LOC\", \"O\"]\n",
    "\n",
    "log_smoothed_probs = apply_smoothing(k, test_counts, vocab)\n",
    "\n",
    "assert len(expected_log_smoothed_probs) == len(log_smoothed_probs)\n",
    "for key in test_counts:\n",
    "    np.testing.assert_almost_equal(expected_log_smoothed_probs[key], log_smoothed_probs[key])\n",
    "\n",
    "\n",
    "# TODO: test this a bit more\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9LWxWrxtgTK"
   },
   "source": [
    "### Milestone submission\n",
    "\n",
    "You can make a milestone submission here. You need to submit your `helpers.py' file to hw1-milestone. The output of this function is expected to be a Python dictionary, where the keys are state-observation tuples, and the corresponding values are the log smoothed observation probabilities. We will not check if the values are exactly correct for the milestone submission, but we will run a basic sanity test to check that your returned dictionary does not contain any 0 probability (or -inf log probability values).\n",
    "\n",
    "In particular, we will check to ensure that all (NER tag, word) pairs with 0 observation counts have been included and assigned log smoothed probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_OtHqyw7CRY"
   },
   "source": [
    "### **HMM Class Implementation**\n",
    "---\n",
    "In this section, you will be implementing the HMM class using the following properties.\n",
    "\n",
    "\n",
    "- **documents**: dataset of sentences to train model\n",
    "- **labels**: NER labels corresponding the sentences to train model\n",
    "- **vocab**: dataset vocabulary\n",
    "- **all_tags**: all possible NER tags\n",
    "- **k_t**: add-k parameter to smooth transition probabilities\n",
    "- **k_e**: add-k parameter to smooth emission probabilities\n",
    "- **k_s**: add-k parameter to smooth starting state probabilities\n",
    "- **smoothing_func**: smoothing function to smooth state-observation probabilities\n",
    "\n",
    "\n",
    "In the `model.py` file, complete following methods under the HMM class:\n",
    "1. `build_transition_matrix()`: returns the transition probabilities as a dictionary, mapping all possible (tag, tag) tuple pairs to their corresponding smoothed log probabilities. See function declaration for more details.\n",
    "\n",
    "2. `build_emission_matrix()`:\n",
    "    returns the emission probabilities as a dictionary, mapping all possible\n",
    "    (tag, token) tuple pairs to their corresponding smoothed log probabilities. See function declaration for more details.\n",
    "    \n",
    "3. `get_start_state_probs()`:\n",
    "    returns the starting state probabilities as a dictionary, mapping all possible\n",
    "    tags to their corresponding smoothed log probabilities. See function declaration for more details.\n",
    "      \n",
    "4. `get_tag_likelihood(predicted_tag, previous_tag, document, i)`\n",
    "     returns the tag likelihood used by the Viterbi algorithm for the log probability of a given\n",
    "    predicted_tag conditioned on the previous_tag and document at index i. See function declaration for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1SHlIyFtgTK"
   },
   "source": [
    "To help you check your implementation, we give you a toy example with only 3 tags: [\"B-PER\", \"O\", \"B-LOC\"]. You may run this following basic test case to test your implementation of build_transition_matrix() and build_emission_matrix(). Passing this test does NOT guarantee correctness and it is a good idea to write some tests of your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "lbqu-xwytgTK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-PER', 'B-LOC', 'O']\n",
      "['Paris', 'in', 'Bob', 'Alice', 'walk', 'and']\n"
     ]
    }
   ],
   "source": [
    "toy_hmm_documents = [['Alice', 'and', 'Bob', 'walk', 'in', 'Paris'], ['Bob', 'and', 'Alice', 'walk', 'in', 'Paris']]\n",
    "toy_hmm_vocab = list(set([item for sublist in toy_hmm_documents for item in sublist]))\n",
    "toy_hmm_ner_tags = [['B-PER', 'O', 'B-PER', 'O', 'O', 'B-LOC'], ['B-PER', 'O', 'B-PER', 'O', 'O', 'B-LOC']]\n",
    "\n",
    "test_hmm_all_tags = list(set([item for sublist in toy_hmm_ner_tags for item in sublist]))\n",
    "print(test_hmm_all_tags)\n",
    "print(toy_hmm_vocab)\n",
    "\n",
    "test_hmm = HMM(toy_hmm_documents, toy_hmm_ner_tags, toy_hmm_vocab, test_hmm_all_tags,\n",
    "          k_t=1, k_e=1, k_s=1, smoothing_func=apply_smoothing)\n",
    "          \n",
    "true_emission_matrix = {\n",
    "    ('B-LOC', 'Bob'): np.log(1/8),\n",
    "    ('B-LOC', 'Alice'): np.log(1/8),\n",
    "    ('B-LOC', 'in'): np.log(1/8),\n",
    "    ('B-LOC', 'and'): np.log(1/8),\n",
    "    ('B-LOC', 'Paris'): np.log(3/8),\n",
    "    ('B-LOC', 'walk'): np.log(1/8),\n",
    "    ('B-PER', 'Bob'): np.log(3/10),\n",
    "    ('B-PER', 'Alice'): np.log(3/10),\n",
    "    ('B-PER', 'in'): np.log(1/10),\n",
    "    ('B-PER', 'and'): np.log(1/10),\n",
    "    ('B-PER', 'Paris'): np.log(1/10),\n",
    "    ('B-PER', 'walk'): np.log(1/10),\n",
    "    ('O', 'Bob'): np.log(1/12),\n",
    "    ('O', 'Alice'): np.log(1/12),\n",
    "    ('O', 'in'): np.log(3/12),\n",
    "    ('O', 'and'): np.log(3/12),\n",
    "    ('O', 'Paris'): np.log(1/12),\n",
    "    ('O', 'walk'): np.log(3/12)\n",
    "}\n",
    "\n",
    "true_transition_matrix = {\n",
    "    ('B-LOC', 'B-LOC'): np.log(1/6),\n",
    "    ('B-LOC', 'B-PER'): np.log(1/6),\n",
    "    ('B-LOC', 'O'): np.log(1/6),\n",
    "    ('B-LOC', 'qf'): np.log(3/6),\n",
    "    ('B-PER', 'B-LOC'): np.log(1/8),\n",
    "    ('B-PER', 'B-PER'): np.log(1/8),\n",
    "    ('B-PER', 'O'): np.log(5/8),\n",
    "    ('B-PER', 'qf'): np.log(1/8),\n",
    "    ('O', 'B-LOC'): np.log(3/10),\n",
    "    ('O', 'B-PER'): np.log(3/10),\n",
    "    ('O', 'O'): np.log(3/10),\n",
    "    ('O', 'qf'): np.log(1/10)\n",
    "}\n",
    "\n",
    "for key in true_emission_matrix:\n",
    "    np.testing.assert_almost_equal(true_emission_matrix[key], test_hmm.emission_matrix[key])\n",
    "\n",
    "for key in true_transition_matrix:\n",
    "    np.testing.assert_almost_equal(true_transition_matrix[key], test_hmm.transition_matrix[key])\n",
    "\n",
    "# TODO: test these more\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hj4pToAtgTK"
   },
   "source": [
    "If needed, you may extend the above example to test your implementation of get_tag_likelihood and get_start_state_probs functions as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-2qQjzT7CRY"
   },
   "source": [
    "\n",
    "After you completed the class methods, call the HMM constructor to train your model with the following criteria:\n",
    "- Note that the input data to train your model will be the training_data[\"text\"] and training_data[\"NER]\n",
    "- First handle unknown words by using your function `handle_unknown_words` from Part 2.1 using a threshold t = 0.01. You should call this function only on the training dataset in this step.\n",
    "- When you call the HMM constructor, use the following smoothing parameters: k_t = 0.01, k_e = 0.01, k_s = 0.1. You should use your smoothing function that you have implemented in Part 2.2\n",
    "- An example call to the HMM constructor is shown in the example above. Note that the values of all_tags and vocab will be different between the toy example above and your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "EKoQ1iHt7CRY"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "all_tags = [\"B-LOC\", \"B-MISC\", \"B-ORG\", \"B-PER\", \"I-LOC\", \"I-MISC\", \"I-ORG\", \"I-PER\", \"O\"]\n",
    "\n",
    "training_text, vocab = handle_unknown_words(t=0.01, documents=training_data['text'])\n",
    "hmm = HMM(training_text, training_data[\"NER\"], vocab, all_tags,\n",
    "          k_t=0.01, k_e=0.01, k_s=0.1, smoothing_func=apply_smoothing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HE8faYCx7CRY"
   },
   "source": [
    "### **Viterbi Implementation**\n",
    "---\n",
    "Implement the function `viterbi(model, observation)` in `viterbi.py` that returns the model's predicted tag sequence for a particular observation. After you have completed the function, use the following cell to see an example tagged sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[('This', 'O', 'O'), ('is', 'O', 'O'), ('the', 'O', 'O'), ('highest', 'O', 'O'), ('approval', 'O', 'O'), ('rate', 'O', 'O'), ('among', 'O', 'O'), ('West', 'B-MISC', 'B-MISC'), ('German', 'B-MISC', 'I-MISC'), ('federal', 'O', 'O'), ('states', 'O', 'O'), ('(', 'O', 'O'), ('average', 'O', 'O'), (':', 'O', 'O'), ('20', 'O', 'O'), ('%', 'O', 'O'), (')', 'O', 'O'), ('and', 'O', 'O'), ('the', 'O', 'O'), ('second', 'O', 'O'), ('highest', 'O', 'O'), ('nationwide', 'O', 'O'), ('(', 'O', 'O'), ('national', 'O', 'O'), ('average', 'O', 'O'), (':', 'O', 'O'), ('24.3', 'O', 'O'), ('%', 'O', 'O'), (')', 'O', 'O')]\n",
      "2\n",
      "[('Questions', 'O', 'O'), ('in', 'O', 'O'), ('Parliament', 'B-ORG', 'O'), ('have', 'O', 'O'), ('not', 'O', 'O'), ('clarified', 'O', 'O'), ('the', 'O', 'O'), ('situation', 'O', 'O'), (',', 'O', 'O'), ('as', 'O', 'O'), ('answers', 'O', 'O'), ('from', 'O', 'O'), ('the', 'O', 'O'), ('relevant', 'O', 'O'), ('minister', 'O', 'O'), ('say', 'O', 'O'), ('that', 'O', 'O'), ('since', 'O', 'O'), ('there', 'O', 'O'), ('is', 'O', 'O'), ('no', 'O', 'O'), ('official', 'O', 'O'), ('national', 'O', 'O'), ('anthem', 'O', 'O'), (',', 'O', 'O'), ('each', 'O', 'O'), ('sport', 'O', 'O'), ('must', 'O', 'O'), ('make', 'O', 'O'), ('its', 'O', 'O'), ('own', 'O', 'O'), ('decision', 'O', 'O')]\n",
      "7\n",
      "[('\"', 'O', 'O'), ('At', 'B-MISC', 'O'), ('Seventeen', 'I-MISC', 'B-ORG'), ('\"', 'O', 'O'), ('is', 'O', 'O'), ('a', 'O', 'O'), ('bittersweet', 'O', 'O'), ('commentary', 'O', 'O'), ('on', 'O', 'O'), ('adolescent', 'O', 'O'), ('cruelty', 'O', 'O'), (',', 'O', 'O'), ('the', 'O', 'O'), ('illusion', 'O', 'O'), ('of', 'O', 'O'), ('popularity', 'O', 'O'), ('and', 'O', 'O'), ('teenage', 'O', 'O'), ('angst', 'O', 'O'), (',', 'O', 'O'), ('from', 'O', 'O'), ('the', 'O', 'O'), ('perspective', 'O', 'O'), ('of', 'O', 'O'), ('a', 'O', 'O'), ('narrator', 'O', 'O'), ('looking', 'O', 'O'), ('back', 'O', 'O'), ('on', 'O', 'O'), ('her', 'O', 'O'), ('earlier', 'O', 'O'), ('experience', 'O', 'O')]\n",
      "14\n",
      "[('Red', 'O', 'B-PER'), ('Easter', 'B-MISC', 'I-PER'), ('eggs', 'O', 'O'), ('are', 'O', 'O'), ('sometimes', 'O', 'O'), ('served', 'O', 'O'), ('along', 'O', 'O'), ('the', 'O', 'O'), ('centerline', 'O', 'O'), ('of', 'O', 'O'), ('tsoureki', 'O', 'O'), ('(', 'O', 'O'), ('braided', 'O', 'O'), ('loaf', 'O', 'O'), ('of', 'O', 'O'), ('bread', 'O', 'O'), (')', 'O', 'O')]\n",
      "19\n",
      "[('In', 'O', 'O'), ('2015', 'O', 'O'), (',', 'O', 'O'), ('there', 'O', 'O'), ('were', 'O', 'O'), ('ten', 'O', 'O'), ('adult', 'O', 'O'), ('education', 'O', 'O'), ('centres', 'O', 'O'), ('in', 'O', 'O'), ('Gothenburg', 'B-LOC', 'B-LOC'), (':', 'O', 'O'), ('\"', 'O', 'O'), ('Agnesbergs', 'B-LOC', 'B-ORG'), ('folkhögskola', 'O', 'I-ORG'), ('\"', 'O', 'O'), (',', 'O', 'O'), ('\"', 'O', 'O'), ('Arbetarrörelsens', 'B-ORG', 'B-ORG'), ('folkhögskola', 'I-ORG', 'I-ORG'), ('i', 'O', 'I-ORG'), ('Göteborg', 'B-LOC', 'I-ORG'), ('\"', 'O', 'O'), (',', 'O', 'O'), ('\"', 'O', 'O'), ('Finska', 'B-ORG', 'B-ORG'), ('folkhögskolan', 'I-ORG', 'I-ORG'), ('\"', 'O', 'O'), (',', 'O', 'O'), ('\"', 'O', 'O'), ('Folkhögskolan', 'B-ORG', 'B-ORG'), ('i', 'I-ORG', 'I-ORG'), ('Angered', 'I-ORG', 'I-ORG'), ('\"', 'O', 'O'), (',', 'O', 'O'), ('\"', 'O', 'O'), ('Göteborgs', 'B-ORG', 'B-ORG'), ('folkhögskola', 'I-ORG', 'I-ORG'), ('\"', 'O', 'O'), (',', 'O', 'O'), ('\"', 'O', 'O'), ('Kvinnofolkhögskolan', 'B-ORG', 'B-ORG'), ('\"', 'O', 'O'), (',', 'O', 'O'), ('\"', 'O', 'O'), ('Mo', 'B-ORG', 'B-ORG'), ('Gård', 'I-ORG', 'I-ORG'), ('folkhögskola', 'I-ORG', 'I-ORG'), ('\"', 'O', 'O'), (',', 'O', 'O'), ('\"', 'O', 'O'), ('S', 'B-ORG', 'B-ORG'), (':', 'I-ORG', 'I-ORG'), ('ta', 'I-ORG', 'I-ORG'), ('Birgittas', 'I-ORG', 'I-ORG'), ('folkhögskola', 'I-ORG', 'I-ORG'), ('\"', 'O', 'O'), (',', 'O', 'O'), ('\"', 'O', 'O'), ('Västra', 'B-ORG', 'B-ORG'), ('Götalands', 'I-ORG', 'I-ORG'), ('folkhögskolor', 'I-ORG', 'I-ORG'), ('\"', 'O', 'O'), ('and', 'O', 'O'), ('\"', 'O', 'O'), ('Wendelsbergs', 'B-ORG', 'B-ORG'), ('folkhögskola', 'I-ORG', 'I-ORG'), ('\"', 'O', 'O')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    obs = training_data['text'][i]\n",
    "    tags = training_data['NER'][i]\n",
    "\n",
    "    predicted = viterbi(hmm, obs, all_tags)\n",
    "    if tags != predicted:\n",
    "        print(i)\n",
    "        print(list(zip(obs, tags, predicted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "J7hADYvi7CRY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags = [\"B-ORG\", \"I-ORG\", \"B-PER\", \"I-PER\", \"B-LOC\", \"I-LOC\", \"B-MISC\", \"I-MISC\", \"O\"]\n",
    "obs = ['The',\n",
    " 'White',\n",
    " 'house',\n",
    " 'located',\n",
    " 'in',\n",
    " 'Ithaca',\n",
    " 'and',\n",
    " 'was',\n",
    " 'founded',\n",
    " 'by',\n",
    " 'Ezra',\n",
    " 'Cornell']\n",
    "\n",
    "# Uncomment and fill out the following line to test your implementation:\n",
    "viterbi(hmm, obs, all_tags) #hmm is the trained model from the previous code block\n",
    "# TODO: test these more\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIBZx5Pb7CRY"
   },
   "source": [
    "### **Validation Step for HMM**\n",
    "---\n",
    "Understanding how models perform on unseen data is important, hence the validation set was set aside to be used in the evaluation of the model. In the previous part of the project, we expected you to train your HMM model (i.e., get transition and emission probabilities) on the labeled training data. Next, you will evaluate your trained model on the validation data. Report **Entity Level Mean F1**, which was explained earlier.\n",
    "\n",
    "**TODO:** complete the function `evaluate_model(model, validation_data, tags)` in the `validation.py` file that takes in a model (HMM) and the validation dataset and returns the Entity Level Mean F1. <br>\n",
    "In the `validation.py` file, you have the following helper methods:\n",
    "- **flatten_double_lst(lstlst)**: Takes in a double nested list and returns the flattened version, row-major\n",
    "- **format_output_labels(token_labels, token_indices)**: Takes in a list of token labels and the corresponding list of token indices and returns a dictionary with mapping NER labels (excluding 'O') to indices that have those labels\n",
    "- **mean_f1(y_pred_dict, y_true_dict)**: Takes in two dictionaries (each mapping NER labels (excluding 'O') to indices that have those labels) that represent predicted labels and truth labels respectively and returns the mean f1 score.\n",
    "\n",
    "Below is an example use case of **format_output_labels(token_labels, token_indices)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "MHNKIF5b7CRY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_dict is : {'LOC': [(18, 18), (28, 28)], 'MISC': [(23, 23)], 'ORG': [(13, 13)], 'PER': [(15, 16)]}\n",
      "y_true_dict is : {'LOC': [(18, 18), (28, 28)], 'MISC': [(23, 24)], 'ORG': [(13, 13)], 'PER': [(15, 16)]}\n",
      "Entity Level Mean F1 score is : 0.75\n"
     ]
    }
   ],
   "source": [
    "pred_token_labels = [\"B-ORG\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"B-LOC\", \"O\", \"O\", \"O\", \"O\", \"B-MISC\", \"O\", \"O\", \"O\", \"O\", \"B-LOC\"]\n",
    "true_token_labels = [\"B-ORG\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"B-LOC\", \"O\", \"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"O\", \"O\", \"O\", \"B-LOC\"]\n",
    "token_indices = [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]\n",
    "\n",
    "y_pred_dict = format_output_labels(pred_token_labels, token_indices)\n",
    "print(\"y_pred_dict is : \" + str(y_pred_dict))\n",
    "y_true_dict = format_output_labels(true_token_labels, token_indices)\n",
    "print(\"y_true_dict is : \" + str(y_true_dict))\n",
    "\n",
    "print(\"Entity Level Mean F1 score is : \" + str(mean_f1(y_pred_dict, y_true_dict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQOECYRV7CRY"
   },
   "source": [
    "After you complete `evaluate_model(model, validation_data, tags)`, use the cell below to evaluate the model using the function you have just implemented. Please also take a look into your misclassified cases, as we will be performing error analysis in next part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mO0ig2f87CRY"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "evaluate_model(hmm, validation_data, all_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9iWDJXS7CRY"
   },
   "source": [
    "### HMM Analysis\n",
    "#### Q2.1: In which situations did the system perform effectively, and when did it encounter challenges? For instance, does the model excel in predicting certain NER tags more than others? Could you offer any hypotheses about the reasons behind these patterns and suggest potential improvements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNjwOrq07CRd"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV1fWqgR7CRd"
   },
   "source": [
    "#### Q2.2: How does the treatment of unknown words and the application of smoothing impact the system's performance? Provide examples to illustrate your insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRKDqWj47CRd"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xDSVSfPtgTR"
   },
   "source": [
    "## **Submission**\n",
    "\n",
    "You will submit your code and code outputs to two different final assingments (note that the submission to the milestone was described previously):\n",
    "\n",
    "### hw1-programming\n",
    "You will submit the 5 python files: `models.py` `helpers.py` `data_exploration.py` `viterbi.py` and `validation.py` to this assignment. Make sure to include your Name(s) and NetIDs at the appropriate place at the top of these files. You can run `check_submission.py` to check if the format of your files is correct. Note that this does not check the correctness of your implementation; that will be done by the autograder on gradescope.\n",
    "\n",
    "\n",
    "### hw1-checktestperformance\n",
    "\n",
    "Since your HMM model is graded based on its performance on the test set, you will submit your model's predictions on test data to this assignment and see the test score. Each student is allowed to submit to this assignment a maximum of 10 times per day, which resets every midnight.\n",
    "\n",
    "For submission, you will generate a file `output.txt` that will contain the predictions of your HMM model on the test data. Below, we provide a function `create_submission(predictions)` that takes in the predicted labels of the test dataset and outputs it in the correct format in `output.txt`. As a scoring metric on Gradescope, we use **Entity Level Mean F1**.\n",
    "\n",
    "To use `create_submission(predictions)`, you want to first train your HMM model on the training dataset (If you have already done this in previous steps, great!). Then, for each sentence in the testing dataset, run your `viterbi` function using your trained HMM model and append the result to a list. Pass in the list to `create_submission`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIqZUaNLtgTR"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "### TODO: Iterate through your test data one document at a time, run viterbi algorithm using your HMM model on that sample and generate predictions. The final output should be (List[List[str]])\n",
    "\n",
    "test_predictions = []\n",
    "for i in range(len(test_data[\"text\"])):\n",
    "    obs = test_data['text'][i]\n",
    "    predicted = viterbi(hmm, obs, all_tags)\n",
    "    test_predictions.append(predicted)\n",
    "\n",
    "\n",
    "def create_submission(test_predictions):\n",
    "    \"\"\"\n",
    "    Parameter:\n",
    "    predictions (List[List[str]]):\n",
    "        Prediction results for the test dataset.\n",
    "        It contains a list of a string list.\n",
    "        Each string list corresponds to a test sentence in the test file.\n",
    "    \"\"\"\n",
    "    with open('output.txt', 'w') as file:\n",
    "        file.write(json.dumps(test_predictions))\n",
    "\n",
    "# Uncomment to use\n",
    "create_submission(test_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
